# TODO: Test for speed vs onehot encoding function, or lapply
for(f in 1:FF){
ohe[[f]] <- matrix(0, nrow = n1 * n2, ncol = n_levels[f])
for(ell in 1:n_levels[f]){
ohe[[f]][comparisons[[f]] == ell, ell] <- 1
}
}
ids <- expand.grid(1:n1, 1:n2)
ids_1 <- ids[, 1]
ids_2 <- ids[, 2]
comparisons <- vector(mode = "list", length = FF)
ohe <- vector(mode = "list", length = FF)
# FS agreement levels
for(f in 1:FF){
if(types[f] == "bi"){
comp <- df1[ids_1, fields_1[f]] == df2[ids_2, fields_2[f]]
comp <- (!comp) + 1
#comparisons[[f]] <- factor(comp)
comparisons[[f]] <- comp
}
if(types[f] == "lv"){
if(distance_metric == "Levenshtein"){
distance <- RecordLinkage::levenshteinDist(as.character(df1[ids_1, fields_1[f]]),
as.character(df2[ids_2, fields_2[f]]))
}
if(distance_metric == "Damerau-Levenshtein"){
# Damerau-Levenshtein distance, so transpositions count as 1.
# In contrast, BRL uses standard Levenshtein, so transpositions count as 2
distance <- 1 - levitate::lev_ratio(as.character(df1[ids_1, fields_1[f]]),
as.character(df2[ids_2, fields_2[f]]),
useNames = F)
}
comp <- cut(distance,
breaks = breaklist[[f]]) %>%
as.integer()
#
# %>%
#   factor(., seq_len(length(breaklist[[f]]) - 1))
comparisons[[f]] <- comp
}
if(types[f] == "nu"){
distance <- abs(df1[ids_1, fields_1[f]] - df2[ids_2, fields_2[f]])
comp <- cut(distance,
breaks = breaklist[[f]]) %>%
as.integer( )
# %>%
#   factor(., seq_len(length(breaklist[[f]]) - 1))
comparisons[[f]] <- comp
}
}
# FS agreement levels
for(f in 1:FF){
if(types[f] == "bi"){
comp <- df1[ids_1, fields_1[f]] == df2[ids_2, fields_2[f]]
comp <- (!comp) + 1
comparisons[[f]] <- factor(comp)
}
if(types[f] == "lv"){
if(distance_metric == "Levenshtein"){
distance <- RecordLinkage::levenshteinDist(as.character(df1[ids_1, fields_1[f]]),
as.character(df2[ids_2, fields_2[f]]))
}
if(distance_metric == "Damerau-Levenshtein"){
# Damerau-Levenshtein distance, so transpositions count as 1.
# In contrast, BRL uses standard Levenshtein, so transpositions count as 2
distance <- 1 - levitate::lev_ratio(as.character(df1[ids_1, fields_1[f]]),
as.character(df2[ids_2, fields_2[f]]),
useNames = F)
}
comp <- cut(distance,
breaks = breaklist[[f]]) %>%
as.integer() %>%
factor(., seq_len(length(breaklist[[f]]) - 1))
comparisons[[f]] <- comp
}
if(types[f] == "nu"){
distance <- abs(df1[ids_1, fields_1[f]] - df2[ids_2, fields_2[f]])
comp <- cut(distance,
breaks = breaklist[[f]]) %>%
as.integer( ) %>%
factor(., seq_len(length(breaklist[[f]]) - 1))
comparisons[[f]] <- comp
}
}
f = 1
types
# Damerau-Levenshtein distance, so transpositions count as 1.
# In contrast, BRL uses standard Levenshtein, so transpositions count as 2
distance <- 1 - levitate::lev_ratio(as.character(df1[ids_1, fields_1[f]]),
as.character(df2[ids_2, fields_2[f]]),
useNames = F)
comp <- cut(distance,
breaks = breaklist[[f]])
comp <- as.integer(comp)
comp <- factor(comp, seq_len(length(breaklist[[f]]) - 1))
roxygen2::roxygenise()
df1 <- read.csv("../../bk_vabl/data/febrl_4_A.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number()) %>%
.[1:100, ]
df2 <- read.csv("../../bk_vabl/data/febrl_4_B.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number()) %>%
.[1:100, ]
n1 <- nrow(df1)
n2 <- nrow(df2)
Z_true <- seq(1:100)
fields <- c(2, 3, 8, 10, 11)
types <- c("lv", "lv","bi", "bi", "bi")
breaks = c(0, .15)
cd <- compare_records(df1, df2, fields = fields, types = types,
breaks = breaks)
hash <- hash_comparisons(cd, all_patterns = F)
out <- vabl(hash)
names(out)[1] == "Z"
names(out)[1] == "pattern_weights"
n2 <- hash$n2
pattern_probs <- lapply(1:n2, function(j){
out$pattern_weights/out$C[j]
})
possible_records <- lapply(1:n2, function(j){
record <- c(hash$flags[[j]]$eligible_records, 0)
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j])
data.frame(record, prob)
})
max_prob <- lapply(possible_records, function(x){
x[which.max(x$prob), ]
}) %>%
do.call(rbind, .)
best_match <- max_prob$record
prob_best_match <- max_prob$prob
prob_no_link <- out$b_pi/out$C
link_indicator <- best_match > 0
results <- estimate_links(out, hash)
results$Z_hat
df1 <- read.csv("../../bk_vabl/data/febrl_4_A.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number())
df2 <- read.csv("../../bk_vabl/data/febrl_4_B.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number())
n1 <- nrow(df1)
n2 <- nrow(df2)
Z_true <- seq(1:100)
fields <- c(2, 3, 8, 10, 11)
types <- c("lv", "lv","bi", "bi", "bi")
breaks = c(0, .15)
start <- tic()
cd <- compare_records(df1, df2, fields = fields, types = types,
breaks = breaks)
hash <- hash_comparisons(cd, all_patterns = F)
out <- vabl(hash)
results <- estimate_links(out, hash)
n2 <- hash$n2
pattern_probs <- lapply(1:n2, function(j){
out$pattern_weights/out$C[j]
})
n2
possible_records <- lapply(1:n2, function(j){
record <- c(hash$flags[[j]]$eligible_records, 0)
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j])
#data.frame(record, prob)
list(record = record,
prob = prob)
})
View(possible_records)
possible_records <- lapply(1:n2, function(j){
record <- c(hash$flags[[j]]$eligible_records, 0)
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j])
data.frame(record)
})
possible_records <- lapply(1:n2, function(j){
record <- c(hash$flags[[j]]$eligible_records, 0)
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j])
data.frame(prob)
})
possible_records <- lapply(1:n2, function(j){
record <- c(hash$flags[[j]]$eligible_records, 0)
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j])
prob
})
View(possible_records)
possible_records
thing <- sapply(possible_records, function(x){
is.na(x) %>%
sum()
})
which(thing > 0)
look_at <- sapply(possible_records, function(x){
is.na(x) %>%
sum()
}) %>%
which()
look_at <- sapply(possible_records, function(x){
is.na(x) %>%
sum()
}) %>%
which(.)
look_at <- sapply(possible_records, function(x){
is.na(x) %>%
sum()
}) %>%
which(. > 0)
look_at <- sapply(possible_records, function(x){
is.na(x) %>%
sum()
})
thing <- sapply(possible_records, function(x){
is.na(x) %>%
sum()
})
look_at <- which(thing > 0)
possible_records[[look_at[1]]]
possible_records[[look_at[2]]]
possible_records[[look_at[3]]]
j = look_at[1]
record <- c(hash$flags[[j]]$eligible_records, 0)
hash$flags[[j]]
c(hash$flags[[j]]$eligible_records, 0)
pattern_probs[[j]]
hash$flags[[j]]$eligible_patterns
View(hash)
possible_records <- lapply(1:n2, function(j){
record <- c(hash$flags[[j]]$eligible_records, 0)
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j])
data.frame(record, prob)
#record
})
j
record <- c(hash$flags[[j]]$eligible_records, 0)
record
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j])
prob
j = 1
record <- c(hash$flags[[j]]$eligible_records, 0)
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j])
prob
record
pattern_probs[[j]]
out$pattern_weights
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j]) %>%
unname()
data.frame(record, prob)
j = look_at[1]
record <- c(hash$flags[[j]]$eligible_records, 0)
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j]) %>%
unname()
data.frame(record, prob)
possible_records <- lapply(1:n2, function(j){
record <- c(hash$flags[[j]]$eligible_records, 0)
prob <- c(pattern_probs[[j]][hash$flags[[j]]$eligible_patterns],
exp(digamma(out$b_pi)) / out$C[j]) %>%
unname()
data.frame(record, prob)
#record
})
devtools::load_all(".")
results <- estimate_links(out, hash)
results$Z_hat
evaluate_links(results$Z_hat, Z_true, n1)
Z_true <- seq(1:5000)
evaluate_links(results$Z_hat, Z_true, n1)
devtools::load_all(".")
knitr::opts_chunk$set(echo = TRUE)
df1 <- read.csv("../../bk_vabl/data/febrl_4_A.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number())
df2 <- read.csv("../../bk_vabl/data/febrl_4_B.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number())
n1 <- nrow(df1)
n2 <- nrow(df2)
Z_true <- seq(1:5000)
fields <- c(2, 3, 8, 10, 11)
types <- c("lv", "lv","bi", "bi", "bi")
breaks = c(0, .15)
cd <- compare_records(df1, df2, fields = fields, types = types,
breaks = breaks)
hash <- hash_comparisons(cd, all_patterns = F)
out <- vabl(hash)
out <- svabl(hash)
k = 1
b_init = TRUE
tau = 1
check_every = 10
store_every = check_every
fixed_iterations = NULL
ohe <- hash$ohe
P <- dim(ohe)[1]
total_counts <- hash$total_counts #N_p
hash_count_list <- hash$hash_count_list
field_marker <- hash$field_marker
n1 <- hash$n1
n2 <- hash$n2
# Priors
alpha <- rep(1, length(field_marker))
Beta <- rep(1, length(field_marker))
alpha_pi <- 1
beta_pi <- 1
# Initialize
a <- rep(1, length(field_marker))
if(b_init == T){
b <- hash$ohe %>%
sweep(., 1, hash$total_counts, "*") %>%
colSums()
} else {
b = rep(1, length(field_marker))
}
a_pi <- 1
b_pi <- 1
t <- 1
ratio <- 1
elbo_seq <- vector()
adjustment <- n2 / B
B
B = min(1000, hash$n2)
ratio
threshold
threshold = 1e-6
tmax = 1000
a_sum <- a %>%
split(., field_marker) %>%
sapply(., sum) %>%
digamma(.) %>%
.[field_marker]
a_chunk <- digamma(a) - a_sum
b_sum <- b %>%
split(., field_marker) %>%
sapply(., sum) %>%
digamma(.) %>%
.[field_marker]
b_chunk <- digamma(b) - b_sum
b_sum <- b %>%
split(., field_marker) %>%
sapply(., sum) %>%
digamma(.) %>%
.[field_marker]
b_sum
b
devtools::load_all(".")
out <- svabl(hash)
out <- svabl(hash)
results <- estimate_links(out, hash)
results$Z_hat
evaluate_links(results$Z_hat, Z_true, n1)
chain <- fabl(hash)
chain <- fabl(hash, S = 100)
results <- estimate_links(out, hash)
evaluate_links(results$Z_hat, Z_true, n1)
df1 <- read.csv("../../bk_vabl/data/febrl_4_A.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number())
df2 <- read.csv("../../bk_vabl/data/febrl_4_B.csv") %>%
arrange(rec_id) %>%
mutate(rec_id = row_number())
df1 <- df1[1:100, ]
df2 <- df2[1:100, ]
4 + 4
cd <-  BRL::compareRecords(df1, df2, flds = fields, types = types,
breaks = breaks)
chain <- BRL::bipartiteGibbs(cd)
unique(cd$comparisons)
cd$comparisons
typeof(cd$comparisons)
class(cd$comparisons)
cd <- compare_records(df1, df2, fields = fields, types = types,
breaks = breaks)
class(cd$comparisons)
devtools::load_all(".")
cd <- compare_records(df1, df2, fields = fields, types = types,
breaks = breaks)
class(cd$comparisons)
unique(cd$comparisons)
chain <- BRL::bipartiteGibbs(cd)
results <- estimate_links(chain, hash)
evaluate_links(results$Z_hat, Z_true, n1)
Z_true <- seq(1:100)
evaluate_links(results$Z_hat, Z_true, n1)
knitr::opts_chunk$set(echo = TRUE)
n1 <- 500
n1 <- 500
n2 <- 500
total_overlap <- n2/2
S = 1000
burn = S * .1
Z_true <- rep(0, n2)
Z_true[1:total_overlap] <- 1:total_overlap
show_progress <- T
fast = F
R <- NULL
all_patterns <- T
m <- c(.05, .95, .05, .95, .05, .95, .05, .95, .05, .95)
u <- c(.99, .01, .99, .01,
1 - 1/30, 1/30, 1 - 1/12, 1/12, 1 - 1/15, 1/15)
levels <- rep(2, 5)
devtools::load_all(".")
cd <- simulate_comparisons(m, u, levels, n1, n2)
cd <- simulate_comparisons(m, u, levels, n1, n2, overlap)
overlap <- n2/2
cd <- simulate_comparisons(m, u, levels, n1, n2, overlap)
dim(cd$comparisons)
field_marker <- unlist(lapply(1:length(levels), function(x){
rep(x, levels[x])
}))
N <- n1 * n2
ids <- expand.grid(1:n1, 1:n2)
indicators <- matrix(NA, nrow = N, ncol = length(levels))
df2matches <- seq_len(overlap)
df1matches <- df2matches + previous_matches
previous_matches = 0
df1matches <- df2matches + previous_matches
Ztrue <- rep(n1 + 1, n2)
Ztrue[df2matches] <- df1matches
match_index <- which(ids[,1]  == (ids[,2]+ previous_matches))[seq_len(overlap)]
m_list <- split(m, field_marker)
u_list <- split(u, field_marker)
gamma_match <- sapply(m_list, function(x){
sample(seq_along(x) - 1, overlap, replace = T, x)
})
gamma_match
gamma_nonmatch <- sapply(u_list, function(x){
sample(seq_along(x) - 1, N - overlap, replace = T, x)
})
if(overlap == 0){
indicators <- gamma_nonmatch
} else {
indicators[match_index,] <- gamma_match
indicators[-match_index,] <- gamma_nonmatch
}
dim(indicators)
ohe <- purrr::map2(data.frame(indicators), levels, ~fs_to_ohe(.x, .y)) %>%
do.call(cbind, .)
FF <- length(levels)
ohe <- vector("list", FF)
ohe[[f]] <- matrix(0, nrow = n1 * n2, ncol = n_levels[f])
ohe[[f]] <- matrix(0, nrow = n1 * n2, ncol = levels[f])
f = 1
ohe[[f]] <- matrix(0, nrow = n1 * n2, ncol = levels[f])
ohe <- vector("list", FF)
for(f in 1:FF){
ohe[[f]] <- matrix(0, nrow = n1 * n2, ncol = levels[f])
for(ell in 1:levels[f]){
ohe[[f]][indicators[, f] == ell, ell] <- 1
}
}
ohe[[1]]
f = 1
ohe[[f]] <- matrix(0, nrow = n1 * n2, ncol = levels[f])
ell = 1
indicators[, f] == ell
ohe[[f]][indicators[, f] == ell, ell] <- 1
ohe[[f]]
gamma_match <- sapply(m_list, function(x){
sample(seq_along(x) - 1, overlap, replace = T, x) + 1
})
gamma_match <- sapply(m_list, function(x){
sample(seq_along(x) - 1, overlap, replace = T, x) + 1
})
gamma_nonmatch <- sapply(u_list, function(x){
sample(seq_along(x) - 1, N - overlap, replace = T, x) + 1
})
m
m <- rep(c(.95, .05), 5)
#m <- c(.05, .95, .05, .95, .05, .95, .05, .95, .05, .95)
m <- rep(c(.95, .05), 5)
# u <- c(.99, .01, .99, .01,
#        1 - 1/30, 1/30, 1 - 1/12, 1/12, 1 - 1/15, 1/15)
u <- c(.01, .99, .01, .99,
1/30, 1- 1/30, 1/12, 1 - 1/12, 1/15, 1 - 1/15)
match_index <- which(ids[,1]  == (ids[,2]+ previous_matches))[seq_len(overlap)]
m_list <- split(m, field_marker)
u_list <- split(u, field_marker)
gamma_match <- sapply(m_list, function(x){
sample(seq_along(x) - 1, overlap, replace = T, x) + 1
})
gamma_nonmatch <- sapply(u_list, function(x){
sample(seq_along(x) - 1, N - overlap, replace = T, x) + 1
})
gamma_nonmatch
if(overlap == 0){
indicators <- gamma_nonmatch
} else {
indicators[match_index,] <- gamma_match
indicators[-match_index,] <- gamma_nonmatch
}
ohe <- vector("list", FF)
for(f in 1:FF){
ohe[[f]] <- matrix(0, nrow = n1 * n2, ncol = levels[f])
for(ell in 1:levels[f]){
ohe[[f]][indicators[, f] == ell, ell] <- 1
}
}
ohe[[f]]
gamma <- do.call(cbind, ohe)
devtools::load_all(".")
cd <- simulate_comparisons(m, u, levels, n1, n2, overlap)
View(cd$comparisons)
roxygen2::roxygenise()
devtools::build_readme()
devtools::build_readme()
devtools::build_readme()
library(vabl)
